{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCGsb8B9nVYF"
      },
      "source": [
        "#Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jSD_ugl-H-r"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import ImageOps, Image\n",
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PCNDcymRdXvU"
      },
      "outputs": [],
      "source": [
        "base_dir = 'PATH_TO_YOUR_DATASET' #@param\n",
        "random.seed(408)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSbS1BlPdXvU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices())\n",
        "# Ref: https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)])\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print('>',e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A3TKmzuym1M"
      },
      "source": [
        "#Image selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDCQpw_CqeOI"
      },
      "outputs": [],
      "source": [
        "print(\">images: %d\"%len(os.listdir(base_dir+'/original/')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1LKy0qXyPy0b"
      },
      "outputs": [],
      "source": [
        "batch_size = 2#@param\n",
        "epochs = 600#@param\n",
        "model_name = \"halftone_edsr\" #@param [\"halftone_edsr\", \"halftone_net\"]\n",
        "image_shape = (256,256)\n",
        "input_zoom = 0.5\n",
        "output_zoom = 1\n",
        "load_pre_trained_model = \"True\" #@param ['True', 'False']\n",
        "load_pre_trained_model = bool(load_pre_trained_model)\n",
        "mode = 'CMYK' #BW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pg5IXdgWtJBM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.tools import module_util\n",
        "#@title Dataset training parameters\n",
        "train_size = 0.7 #@param\n",
        "validation_split = 2/3 #@param\n",
        "k_fold = 5 #@param\n",
        "example_folds = [{'train':[],'test':[]} for i in range(k_fold)]\n",
        "output_path = \"OUTPUT_PATH\"\n",
        "\n",
        "example_images = os.listdir(base_dir+'/original/')\n",
        "\n",
        "random.shuffle(example_images)\n",
        "example_images = example_images[:900]\n",
        "\n",
        "size_fold = int(len(example_images)*train_size)\n",
        "\n",
        "\n",
        "print(size_fold)\n",
        "for fold in range(k_fold):\n",
        "  example_folds[fold]['train'] += [base_dir+'/%s/'+v+'.npy' for v in example_images[:size_fold]]\n",
        "  example_folds[fold]['test']  += [base_dir+'/%s/'+v+'.npy' for v in example_images[size_fold:]]\n",
        "  example_images = example_images[size_fold:] + example_images[:size_fold]\n",
        "\n",
        "  if(validation_split):\n",
        "    size_val = int(validation_split*len(example_folds[fold]['test']))\n",
        "    example_folds[fold]['validation'] = example_folds[fold]['test'][:size_val]\n",
        "    example_folds[fold]['test'] = example_folds[fold]['test'][size_val:]\n",
        "\n",
        "\n",
        "for i in range(k_fold):\n",
        "  print(\"#%d fold\"%i)\n",
        "  for t in ['train', 'validation', 'test']:\n",
        "    print('\\t>',\"%s:\"%t,len(example_folds[i][t]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lviaF9igdXvV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqwSwz-O4g2O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class HalftoneModel(tf.keras.Model):\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def predict_step(self, xs):\n",
        "        if(mode == 'BW'):\n",
        "          xs = tf.cast(tf.expand_dims(xs, axis=3), tf.float32)\n",
        "        else:\n",
        "          xs = tf.cast(xs, tf.float32)\n",
        "\n",
        "        outputs = []\n",
        "        for x in xs:\n",
        "          x = tf.cast(tf.expand_dims(x, axis=0), tf.float32)\n",
        "          output = self(x, training=False)\n",
        "          output = 255*output\n",
        "          output = tf.clip_by_value(output, 0, 255)\n",
        "          output = tf.round(output)\n",
        "\n",
        "          if(mode == 'BW'):\n",
        "            output = tf.squeeze(tf.cast(output, tf.uint8), axis=0)\n",
        "          else:\n",
        "            output = tf.cast(output, tf.uint8)\n",
        "\n",
        "          outputs.append(output)\n",
        "        return np.array(outputs)\n",
        "\n",
        "# Residual Block\n",
        "def ResBlock(inputs, kernel = 3):\n",
        "\n",
        "    x = layers.Conv2D(2**(9-kernel), kernel, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = layers.Conv2D(64, kernel, padding=\"same\")(x)\n",
        "    x = layers.Add()([inputs, x])\n",
        "    return x\n",
        "\n",
        "# Upsampling Block\n",
        "def Upsampling(inputs, qt_inputs, factor=2, **kwargs):\n",
        "    x = layers.Conv2D(qt_inputs* 64 * (factor ** 2), 3, padding=\"same\", **kwargs)(inputs)\n",
        "    x = tf.nn.depth_to_space(x, block_size=factor)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teVUsEGPdXvW"
      },
      "outputs": [],
      "source": [
        "def hafltone_edsr(num_filters, num_of_residual_blocks):\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    if(mode == 'CMYK'):\n",
        "      input_layer = layers.Input(shape=(None, None, 4))\n",
        "    else:\n",
        "      input_layer = layers.Input(shape=(None, None, 1))\n",
        "\n",
        "    x = input_layer\n",
        "    x = x_new = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "\n",
        "    for _ in range(num_of_residual_blocks):\n",
        "        x_new = ResBlock(x_new, None)\n",
        "\n",
        "    x_new = layers.Conv2D(num_filters, 3, padding=\"same\")(x_new)\n",
        "    x = layers.Add()([x, x_new])\n",
        "\n",
        "    up_layers = np.log2(output_zoom/input_zoom)\n",
        "\n",
        "    if(int(up_layers) != up_layers):\n",
        "      raise Exception(\"The input and output resolution must be in base 2! Current ratio: %.2f \"%(output_zoom/input_zoom))\n",
        "\n",
        "    for _ in range(int(up_layers)):\n",
        "      x = Upsampling(x, 1, factor=2**up_layers)\n",
        "\n",
        "    if(mode == 'CMYK'):\n",
        "      output_layer = layers.Conv2D(4, 3, padding=\"same\")(x)\n",
        "    else:\n",
        "      output_layer = layers.Conv2D(1, 3, padding=\"same\")(x)\n",
        "\n",
        "    model =  HalftoneModel(input_layer, output_layer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFwQV4CtdXvW"
      },
      "outputs": [],
      "source": [
        "def hafltone_net(num_filters, num_of_residual_blocks):\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    if(mode == 'CMYK'):\n",
        "      input_layer = layers.Input(shape=(None, None, 4))\n",
        "    else:\n",
        "      input_layer = layers.Input(shape=(None, None, 1))\n",
        "\n",
        "    x = input_layer\n",
        "    x = x_new = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "\n",
        "    for _ in range(num_of_residual_blocks):\n",
        "        x_new = ResBlock(x_new, None)\n",
        "\n",
        "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(x_new)\n",
        "\n",
        "    up_layers = np.log2(output_zoom/input_zoom)\n",
        "\n",
        "    if(int(up_layers) != up_layers):\n",
        "      raise Exception(\"The input and output resolution must be in base 2! Current ratio: %.2f \"%(output_zoom/input_zoom))\n",
        "\n",
        "    for _ in range(int(up_layers)):\n",
        "      x = Upsampling(x, 2, factor=2**up_layers)\n",
        "\n",
        "    if(mode == 'CMYK'):\n",
        "      output_layer = layers.Conv2D(4, 3, padding=\"same\")(x)\n",
        "    else:\n",
        "      output_layer = layers.Conv2D(1, 3, padding=\"same\")(x)\n",
        "\n",
        "    model =  HalftoneModel(input_layer, output_layer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7EjiWnoToGg"
      },
      "source": [
        "##Model types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuQ-TWLCS4js"
      },
      "outputs": [],
      "source": [
        "model_by_name = {\n",
        "    'halftone_net': \"()\",\n",
        "    'halftone_edsr' : \"(num_filters=64, num_of_residual_blocks=16)\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvlZtkPacLmO"
      },
      "source": [
        "##Model Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D8Jo8t-dXvX"
      },
      "source": [
        "In halftone photography, the term amplitude modulation is used to refer to a halftoning technique (the conventional form of halftone screening) in which the sizes of the halftone dots are varied according to whether they correspond to shadows (large dots), middle tones (medium-sized dots), or highlights (small dots). An alternate means of halftone screening is known as stochastic screening, or FM screening. See Halftone and Stochastic Screening.\n",
        "<a src=\"http://printwiki.org/Amplitude_Modulation#:~:text=In%20halftone%20photography%2C%20the%20term,highlights%20(small%20dots).\">source</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U16og5fF9Uee"
      },
      "outputs": [],
      "source": [
        "model = eval(model_name+model_by_name[model_name])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHKqk4L5GRf7"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic5Dts_6KTcF"
      },
      "source": [
        "#Prepare the dataset for the created model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9nsVUYJS4gZ"
      },
      "outputs": [],
      "source": [
        "model_shape = model.output.shape[1:3][::-1]\n",
        "if(model != 'BW'):\n",
        "  model_shape+=model.output.shape[3]\n",
        "print(model_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f8GQ4kMPmCF"
      },
      "outputs": [],
      "source": [
        "#@title DataGenerator\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def slice_images(self,xs,ys):\n",
        "    ret_x, ret_y = [],[]\n",
        "    x = 1-np.load(xs)/255\n",
        "    y = 1-np.load(ys)/255\n",
        "    if(mode == 'BW'):\n",
        "      x = np.expand_dims(x[:,:,0],-1)\n",
        "      y = np.expand_dims(y[:,:,0],-1)\n",
        "    i = 0\n",
        "\n",
        "    x1,y1 = random.randint(0,x.shape[0]-image_shape[0]-1), random.randint(0,x.shape[1]-image_shape[1]-1)\n",
        "    x2,y2 = x1+image_shape[0],y1+image_shape[1]\n",
        "    v = np.mean(y[x1:x2,y1:y2])\n",
        "    if(True or v >= 0.02):\n",
        "        ret_x.append(x[x1:x2,y1:y2:,])\n",
        "        ret_y.append(y[x1*2:2*x2,y1*2:2*y2:,])\n",
        "        i += 1\n",
        "    return ret_x[0], ret_y[0]\n",
        "\n",
        "  def __init__(self, dataset_images, oversampling = 1, shuffle=True, batch_size = 3, name = \"\", only_class = None, slice_once = False):\n",
        "\n",
        "    self.slice_once = slice_once\n",
        "    if(name == 'train'):\n",
        "      self.dataset_images = ([v.replace(\"/%s/\",'/halfsize/') for v in dataset_images*oversampling], [v.replace(\"/%s/\",'/real/') for v in dataset_images*oversampling])\n",
        "    else:\n",
        "      self.dataset_images = ([v.replace(\"/%s/\",'/halfsize/') for v in dataset_images], [v.replace(\"/%s/\",'/real/') for v in dataset_images])\n",
        "\n",
        "    if(name == 'train'):\n",
        "      self.batch_size = batch_size\n",
        "    else:\n",
        "      self.batch_size = 1\n",
        "\n",
        "    self.name = name\n",
        "    self.data_aug = ['train']\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.steps_per_epoch\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    if(index >= np.floor(self.steps_per_epoch)):\n",
        "      indexes = self.indexes[index*self.batch_size:]\n",
        "    else:\n",
        "      indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    list_IDs_temp = [(self.dataset_images[0][k],self.dataset_images[1][k]) for k in indexes]\n",
        "    return self.__data_generation(list_IDs_temp)\n",
        "\n",
        "  def data_augmentation(self,a,b):\n",
        "    pass\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    if(self.batch_size == 1):\n",
        "      self.steps_per_epoch = len(self.dataset_images[0])\n",
        "    else:\n",
        "      self.steps_per_epoch = (len(self.dataset_images[0]) // self.batch_size) +1 if(self.batch_size > 1) else 1\n",
        "    self.indexes = np.arange(len(self.dataset_images[0]))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def _datagen(self, list_IDs_temp):\n",
        "    if(self.name == 'train'):\n",
        "      if(mode == 'BW'):\n",
        "        X = np.empty((len(list_IDs_temp), image_shape[1], image_shape[0],1), dtype = np.float32)\n",
        "        Y = np.empty((len(list_IDs_temp), 2*image_shape[1], 2*image_shape[0],1), dtype = np.float32)\n",
        "      else:\n",
        "        X = np.empty((len(list_IDs_temp), image_shape[1], image_shape[0],4), dtype = np.float32)\n",
        "        Y = np.empty((len(list_IDs_temp), 2*image_shape[1], 2*image_shape[0],4), dtype = np.float32)\n",
        "\n",
        "      for i,d in enumerate(list_IDs_temp):\n",
        "        (x,y) = self.slice_images(*d)\n",
        "        X[i,],Y[i,] = x,y\n",
        "    else:\n",
        "      X,Y = None,None\n",
        "\n",
        "      for i,d in enumerate(list_IDs_temp):\n",
        "        x,y = 1-np.load(d[0])/255, 1-np.load(d[1])/255\n",
        "        if(X is None):\n",
        "          if(mode == 'BW'):\n",
        "            X = np.empty((len(list_IDs_temp), (x.shape[0]//2)*2 -1 , (x.shape[1]//2)*2 - 1,1), dtype = np.float32)\n",
        "            Y = np.empty((len(list_IDs_temp), X.shape[1]*2, X.shape[2]*2, 1), dtype = np.float32)\n",
        "          else:\n",
        "            X = np.empty((len(list_IDs_temp), (x.shape[0]//2)*2 -1 , (x.shape[1]//2)*2 - 1,4), dtype = np.float32)\n",
        "            Y = np.empty((len(list_IDs_temp), X.shape[1]*2, X.shape[2]*2, 4), dtype = np.float32)\n",
        "        if(mode == 'BW'):\n",
        "          x = np.expand_dims(x[:,:,0],-1)\n",
        "          y = np.expand_dims(y[:,:,0],-1)\n",
        "        X[i,] = x[:X.shape[1], : X.shape[2]:, :]\n",
        "        Y[i,] = y[:Y.shape[1], : Y.shape[2]:, :]\n",
        "    return X,Y\n",
        "\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    return self._datagen(list_IDs_temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MJpWHEHQ8UT"
      },
      "outputs": [],
      "source": [
        "all_datasets = []\n",
        "for fold in example_folds:\n",
        "    all_datasets.append({})\n",
        "    for key in fold:\n",
        "        all_datasets[-1][key] = DataGenerator(fold[key], batch_size = batch_size, name=key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq48YKbA6B_r"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "def PSNR(im1, im2):\n",
        "  max_pixel = 1.0\n",
        "  return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(im2 - im1)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnF8EHFTACpL"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "def SSIM(im1, im2):\n",
        "  return tf.image.ssim(im1, im2, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PilgBsT8KWos"
      },
      "source": [
        "#Main Routine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfQpyzEYdXvY"
      },
      "outputs": [],
      "source": [
        "base_resultados = output_path+'/'\n",
        "nome_pasta = '/'+model_name+'/'\n",
        "export_folder_name = base_resultados+nome_pasta\n",
        "try:\n",
        "    os.mkdir(export_folder_name)\n",
        "except FileExistsError:\n",
        "    pass\n",
        "export_folder_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oyu8iYEdXvZ"
      },
      "outputs": [],
      "source": [
        "loss_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    export_folder_name+model_name+'.h5', monitor='val_loss', mode='min', verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25PqMYmk9VQg"
      },
      "outputs": [],
      "source": [
        "optim_edsr = tf.keras.optimizers.Adam(\n",
        "    learning_rate=tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=[5000], values=[5e-4, 5e-5]\n",
        "    )\n",
        ")\n",
        "model.compile(optimizer=optim_edsr, loss=\"mse\", metrics=[tf.keras.losses.MeanAbsoluteError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYhxy4EzdXvZ"
      },
      "outputs": [],
      "source": [
        "def test_model(datasets, model):\n",
        "  m_ss, m_mae, m_dbs = [], [], []\n",
        "  img_idx = 0\n",
        "  for k in ['test', 'validation']:\n",
        "    for v in datasets[k]:\n",
        "      if(mode == 'CMYK2BW' and len(v[0].shape) > 2):\n",
        "          result = np.array([model.predict_step(v[0][:,:,:,c]).squeeze() for c in range(v[0].shape[-1])])\n",
        "          result = np.expand_dims(np.moveaxis(result, 0, -1), axis=0)\n",
        "      else:\n",
        "          result = model.predict_step(v[0])\n",
        "      for img,res in zip(v[1], result):\n",
        "        img = img.squeeze()\n",
        "        res = res.squeeze().astype(np.float32)/255\n",
        "        v = np.ma.masked_invalid(PSNR(img, res).numpy())\n",
        "        m_dbs.append(v.mean())\n",
        "        m_mae.append(abs(((img-res))).mean())\n",
        "        if(mode == 'BW'):\n",
        "          m_ss.append(ssim(img,res, data_range = 1.0))\n",
        "        else:\n",
        "          m_ss.append(ssim(img,res, data_range = 1.0, channel_axis = 2))\n",
        "        img_idx += 1\n",
        "  a , b , c = np.mean(m_mae), np.mean(m_dbs), np.mean(m_ss)\n",
        "\n",
        "  return \"All images mean: MAE: %.8f, PSNR: %.8fdB, SSIM: %.8f\"%(a,b,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMvfrQs3bOV2"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# ===========================================================\n",
        "count = 1\n",
        "for idx_data, datasets in enumerate(all_datasets):\n",
        "  model = eval(model_name+model_by_name[model_name])\n",
        "\n",
        "  optim_edsr = tf.keras.optimizers.Adam(\n",
        "    learning_rate=tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[5000], values=[5e-4, 1e-5])\n",
        "  )\n",
        "\n",
        "  model.compile(optimizer=optim_edsr, loss=\"mse\", metrics=[tf.keras.losses.MeanAbsoluteError(), tf.keras.losses.MeanSquaredError()])\n",
        "  if(not load_pre_trained_model):\n",
        "\n",
        "    history = model.fit(\n",
        "        datasets['train'],\n",
        "        validation_data=datasets['validation'],\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    model.save_weights(export_folder_name+model_name+'_%d.h5'%idx_data)\n",
        "    with open(export_folder_name+'dataset_%d.pck'%idx_data,'wb+') as f:\n",
        "      pickle.dump(datasets,f)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import json\n",
        "\n",
        "    try:\n",
        "      with open(export_folder_name+'history_%d.json'%idx_data) as f:\n",
        "        hist = json.load(f)\n",
        "      for key in hist:\n",
        "        hist[key] += history.history[key]\n",
        "      with open(export_folder_name+'history_%d.json'%idx_data, 'w+') as f:\n",
        "        json.dump(hist,f)\n",
        "    except FileNotFoundError:\n",
        "      with open(export_folder_name+'history_%d.json'%idx_data, 'w+') as f:\n",
        "        json.dump(history.history,f)\n",
        "      hist = history.history\n",
        "\n",
        "    with open(export_folder_name+'history_%d.json'%idx_data, 'w+') as f:\n",
        "      json.dump(history.history,f)\n",
        "    hist = history.history\n",
        "\n",
        "    metrics_val = {}\n",
        "\n",
        "    metrics = []\n",
        "    tem_val = False\n",
        "    for metric in hist:\n",
        "      if (('val_'+metric in hist)):\n",
        "        tem_val = True\n",
        "        metrics.append(metric)\n",
        "    if(not tem_val):\n",
        "      metrics = [metric for metric in hist]\n",
        "\n",
        "    fig, ax = plt.subplots(nrows = len(metrics), ncols= 1, figsize=(10, 5*len(metrics)))\n",
        "    ax = ax.ravel()\n",
        "\n",
        "    i = 0\n",
        "    for metric in (metrics):\n",
        "      ax[i].plot(hist[metric])\n",
        "      v = \"val_\" + metric\n",
        "      if(v in hist):\n",
        "        ax[i].plot(hist[v])\n",
        "      ax[i].set_title(\"Model {}\".format(metric))\n",
        "      ax[i].set_xlabel(\"epochs\")\n",
        "      ax[i].set_ylabel(metric)\n",
        "      ax[i].legend([\"train\", \"val\"])\n",
        "      i += 1\n",
        "    plt.savefig(export_folder_name+'/histÃ³rico_%d.png'%idx_data)\n",
        "\n",
        "  else:\n",
        "    model.load_weights(export_folder_name+model_name+'_%d.h5'%idx_data)\n",
        "\n",
        "\n",
        "  relatorio = test_model(datasets,model)\n",
        "  print(relatorio)\n",
        "\n",
        "  from skimage.metrics import structural_similarity as ssim\n",
        "  # ===========================================================\n",
        "  if(mode == 'BW'):\n",
        "    c_mode = 'L'\n",
        "  elif(mode == 'CMYK'):\n",
        "    c_mode = 'CMYK'\n",
        "  # ===========================================================\n",
        "  buffer_tests = \"\"\n",
        "  # ===========================================================\n",
        "  for t_dataset in ['validation','test']:\n",
        "    for v in datasets[t_dataset]:\n",
        "      if(mode == 'CMYK2BW' and len(v[0].shape) > 2):\n",
        "          result = np.array([model.predict_step(v[0][:,:,:,c]).squeeze() for c in range(v[0].shape[-1])])\n",
        "          result = np.expand_dims(np.moveaxis(result, 0, -1), axis=0)\n",
        "      else:\n",
        "          result = model.predict_step(v[0])\n",
        "      # ===========================================================\n",
        "      for i,img in enumerate(v[0]):\n",
        "        name = export_folder_name+'/%d_input.png'%(i+(count-1))\n",
        "        img = 1-img.squeeze()\n",
        "        Image.fromarray(np.array(255*img, dtype=np.uint8), mode = c_mode).convert('RGB').save(name)\n",
        "      # ===========================================================\n",
        "      for i,img in enumerate(v[1]):\n",
        "        name = export_folder_name+'/%d_ideal.png'%(i+(count-1))\n",
        "        img = 1-img.squeeze()\n",
        "        Image.fromarray(np.array(255*img, dtype=np.uint8), mode = c_mode).convert('RGB').save(name)\n",
        "      # ===========================================================\n",
        "      for i,(img,res_i) in enumerate(zip(v[1], result)):\n",
        "        res = res_i.squeeze().astype(np.float32)/255\n",
        "        img = img.squeeze()\n",
        "        v = np.ma.masked_invalid(PSNR(img, res).numpy())\n",
        "        dbs = (v.mean())\n",
        "        mae = abs(((img-res))).mean()\n",
        "        if(mode == 'BW'):\n",
        "          ss = ssim(img,res, data_range = 1.0)\n",
        "        else:\n",
        "          ss = ssim(img,res, data_range = 1.0, channel_axis = 2)\n",
        "        buffer_tests += \"Imagem: %d | MAE: %.5f | PSNR: %.8f dBs | SSIM: %.8f\\n\"%((i+(count-1)), mae,dbs, ss)\n",
        "      # ===========================================================\n",
        "      for i,img in enumerate(result):\n",
        "        img = 255-img.squeeze()\n",
        "        name = export_folder_name+\"%d_resultado.png\"%(i+(count-1))\n",
        "        Image.fromarray(np.array(img.squeeze(), dtype=np.uint8), mode = c_mode).convert('RGB').save(name)\n",
        "      count += datasets[t_dataset].batch_size\n",
        "\n",
        "\n",
        "    with open(export_folder_name+'/relatorio_%d.txt'%idx_data, 'w+') as f:\n",
        "      f.write(buffer_tests+relatorio+'\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "601a9e3c729875f38a55deb65c16faf26d926a99faad2ee0fcc7346e8f239414"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}